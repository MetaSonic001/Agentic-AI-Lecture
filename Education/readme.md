# ğŸ”¬ Multi-Agent Research Assistant (Agno)

A true multi-agent research system built with **Agno (formerly Phidata)** framework for autonomous research and report generation.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AGNO TEAM AGENT                               â”‚
â”‚              (Multi-Agent Coordinator)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        â”â”â”â”â”â”â”â”â”â”â”â”»â”â”â”â”â”â”â”â”â”â”â”“
        â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚PLANNER AGENT â”‚      â”‚      WORKER AGENT              â”‚
â”‚              â”‚      â”‚                                â”‚
â”‚ Role:        â”‚      â”‚ Role: Execution Specialist     â”‚
â”‚ Planning     â”‚â”€â”€â”€â”€â”€â–¶â”‚                                â”‚
â”‚ Expert       â”‚      â”‚ Tools:                         â”‚
â”‚              â”‚      â”‚ â”œâ”€ search_web()                â”‚
â”‚ Creates:     â”‚      â”‚ â”œâ”€ extract_webpage_content()   â”‚
â”‚ â€¢ Research   â”‚      â”‚ â”œâ”€ analyze_text_statistics()   â”‚
â”‚   Plan       â”‚      â”‚ â”œâ”€ analyze_sentiment()         â”‚
â”‚ â€¢ Task List  â”‚      â”‚ â””â”€ create_visualization()      â”‚
â”‚ â€¢ Strategy   â”‚      â”‚                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ Executes:                      â”‚
                      â”‚ 1. Source Collection           â”‚
                      â”‚ 2. Content Extraction          â”‚
                      â”‚ 3. Data Analysis               â”‚
                      â”‚ 4. Report Writing              â”‚
                      â”‚ 5. Self-Review                 â”‚
                      â”‚ 6. Final Production            â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Key Features

### ğŸ¤– True Multi-Agent System (Agno)
- **Team-based coordination**: Agents work together seamlessly
- **Built-in orchestration**: No manual handoffs needed
- **Tool-equipped agents**: Workers have specialized capabilities
- **Autonomous execution**: Agents make decisions independently

### ğŸ“š Comprehensive Research
- Web search via DuckDuckGo (no API key needed)
- Content extraction from multiple sources
- Text statistics and keyword analysis
- Sentiment analysis
- Auto-generated visualizations

### ğŸ“Š Rich Outputs
- Multi-section research reports
- Statistical summaries
- Keyword charts and word clouds
- Sentiment analysis gauges
- Markdown and downloadable formats

## ğŸ“ Project Structure

```
multi-agent-research/
â”œâ”€â”€ app.py                 # Streamlit UI
â”œâ”€â”€ agents.py              # Agno agent definitions
â”œâ”€â”€ orchestrator.py        # Research workflow orchestrator
â”œâ”€â”€ tools.py               # Agent tools (search, extract, analyze)
â”œâ”€â”€ models.py              # Data models
â”œâ”€â”€ config.py              # Configuration
â”œâ”€â”€ logger_setup.py        # Logging
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ .env.example           # Environment template
â””â”€â”€ README.md              # Documentation
```

## ğŸš€ Installation & Setup

### 1. Prerequisites
- Python 3.9+
- pip

### 2. Clone/Create Project
```bash
mkdir multi-agent-research
cd multi-agent-research
# Copy all files from artifacts
```

### 3. Virtual Environment
```bash
python -m venv venv

# Activate:
# Linux/Mac:
source venv/bin/activate

# Windows:
venv\Scripts\activate
```

### 4. Install Dependencies
```bash
pip install -r requirements.txt
```

### 5. Get Groq API Key (FREE)
1. Visit [console.groq.com](https://console.groq.com)
2. Sign up (no credit card required)
3. Create an API key
4. Free tier includes:
   - 30 requests/minute
   - 6,000 requests/day
   - Plenty for research tasks!

### 6. Configure Environment
```bash
cp .env.example .env
nano .env  # or use any editor

# Add your key:
GROQ_API_KEY=gsk_your_actual_key_here
```

### 7. Run Application
```bash
streamlit run app.py
```

Application opens at: `http://localhost:8501`

## ğŸ¯ Usage

### Basic Workflow

1. **Enter Topic**: Type your research question in the sidebar
   - Example: "Applications of machine learning in healthcare"
   
2. **Click Start**: Agents begin autonomous research
   
3. **Watch Progress**: Real-time status updates show agent activities
   
4. **Review Results**: 
   - Research plan from Planner Agent
   - Complete report from Worker Agent
   - Visualizations and statistics
   
5. **Download**: Get your report in Markdown format

### Example Topics

- "Sentiment analysis applications in social media"
- "Recent advances in quantum computing"
- "Climate change mitigation strategies"
- "Blockchain technology use cases"
- "Artificial intelligence ethics considerations"

## ğŸ› ï¸ How It Works

### Phase 1: Planning (Planner Agent)
```
Input: Research Topic
â†“
Planner Agent analyzes and creates:
â”œâ”€ Task 1: Source Identification
â”œâ”€ Task 2: Content Collection
â”œâ”€ Task 3: Data Analysis
â”œâ”€ Task 4: Report Drafting
â”œâ”€ Task 5: Self-Review
â””â”€ Task 6: Final Production
```

### Phase 2: Execution (Worker Agent)
```
Worker Agent with Tools:
â”‚
â”œâ”€ Task 1: search_web()
â”‚   â””â”€ Find 3-5 trustworthy sources
â”‚
â”œâ”€ Task 2: extract_webpage_content()
â”‚   â””â”€ Scrape and clean content
â”‚
â”œâ”€ Task 3: analyze_text_statistics() + analyze_sentiment()
â”‚   â””â”€ Generate statistics and sentiment scores
â”‚
â”œâ”€ Task 4: LLM-powered writing
â”‚   â””â”€ Draft report sections
â”‚
â”œâ”€ Task 5: Self-review loop
â”‚   â””â”€ Critique and improve draft
â”‚
â””â”€ Task 6: create_visualization() + formatting
    â””â”€ Final report with charts
```

## âš™ï¸ Configuration

Edit `config.py`:

```python
# LLM Settings
LLM_MODEL = "llama-3.1-70b-versatile"  # Groq's most capable
LLM_TEMPERATURE = 0.7                   # Creativity level
MAX_TOKENS = 8192                       # Response length

# Research Settings
MAX_SOURCES = 3                         # Sources to collect
MAX_SEARCH_RESULTS = 5                  # Search results to consider

# Review Settings
MAX_REVIEW_ITERATIONS = 2               # Self-review cycles
```

## ğŸ§° Tech Stack

| Component | Technology | Why |
|-----------|-----------|-----|
| **Multi-Agent** | Agno (formerly Phidata) | True agent coordination |
| **LLM** | Groq + Llama 3.1 70B | Fast, free, powerful |
| **Search** | DuckDuckGo | No API key needed |
| **Scraping** | BeautifulSoup4 | Reliable extraction |
| **Analysis** | TextBlob | Sentiment analysis |
| **Viz** | Matplotlib, WordCloud | Charts and word clouds |
| **UI** | Streamlit | Clean, reactive interface |
| **Logging** | Loguru | Beautiful logs |

## ğŸ“ Agent Instructions

### Planner Agent
```
Role: Research Planning Expert
Responsibilities:
- Analyze research topic
- Break down into subtasks
- Create structured 6-task plan
- Coordinate with Worker Agent
```

### Worker Agent
```
Role: Research Execution Specialist
Tools: 5 specialized functions
Responsibilities:
- Execute all research tasks
- Use tools autonomously
- Collect and analyze data
- Write and review content
- Produce final outputs
```

## ğŸ› Troubleshooting

### "GROQ_API_KEY not found"
```bash
# Check .env file exists
ls -la .env

# Verify contents
cat .env

# Should show:
# GROQ_API_KEY=gsk_...

# Restart app after changes
```

### "Search failed"
- Check internet connection
- DuckDuckGo may rate-limit; wait 30 seconds and retry
- Try a different search query

### "Agent not responding"
- Check Groq API status: [status.groq.com](https://status.groq.com)
- Verify API key is valid
- Check rate limits (30 req/min on free tier)

### Charts not generating
```bash
# Install matplotlib dependencies (Linux)
sudo apt-get install python3-tk

# Verify matplotlib backend
python -c "import matplotlib; print(matplotlib.get_backend())"
# Should show 'Agg'
```

## ğŸ“ Educational Value

This project demonstrates:
- âœ… Multi-agent coordination (Agno)
- âœ… Tool-equipped agents
- âœ… Autonomous task execution
- âœ… LLM integration (Groq)
- âœ… Web scraping best practices
- âœ… Text analysis techniques
- âœ… Data visualization
- âœ… Clean code architecture
- âœ… Comprehensive logging
- âœ… Modern UI/UX (Streamlit)

## ğŸ”® Future Enhancements

Possible additions:
- [ ] Add fact-checking agent
- [ ] Implement RAG for better context
- [ ] Add PDF export
- [ ] Include citation management
- [ ] Multi-language support
- [ ] Collaborative editing agent
- [ ] Research history and caching

## ğŸ“„ License

MIT License - Free to use and modify!

## ğŸ¤ Contributing

This is an educational project. Feel free to fork and extend!

## ğŸ“š Resources

- [Agno Documentation](https://docs.agno.com)
- [Agno GitHub](https://github.com/agno-agi/agno)
- [Groq Documentation](https://console.groq.com/docs)
- [Streamlit Documentation](https://docs.streamlit.io)

---

**Built with â¤ï¸ using Agno Multi-Agent Framework**